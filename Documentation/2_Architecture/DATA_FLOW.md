# Klick - Data Flow Architecture

**Last Updated**: October 30, 2025  
**Purpose**: Complete data flow diagrams and patterns

---

## ğŸ”„ Overview

This document maps how data flows through Klick from user actions to UI updates, covering camera frames, state changes, and asynchronous operations.

---

## ğŸ“¹ Camera Frame Processing Pipeline

### High-Level Flow

```
Camera Hardware
    â†“ [30 FPS]
AVCaptureVideoDataOutput
    â†“ [Sample Buffer Delegate]
CameraView.Coordinator
    â†“ [Frame Throttling - Every 3rd frame]
CVPixelBuffer Extraction
    â†“ [Background Queue]
Vision Framework
    â†“ [Face/Human Detection]
VNObservation Results
    â†“ [Coordinate Conversion]
CompositionManager
    â†“ [Service Evaluation]
CompositionResult
    â†“ [Main Queue]
SwiftUI State Update
    â†“ [Automatic Rendering]
UI Update (Overlays + Feedback)
```

### Detailed Frame Processing

```swift
// STEP 1: Frame Arrival (30 FPS)
func captureOutput(
    _ output: AVCaptureOutput,
    didOutput sampleBuffer: CMSampleBuffer,
    from connection: AVCaptureConnection
) {
    // STEP 2: Stability & Throttling Checks
    guard cameraReady else { return }
    guard currentTime - cameraStartTime > 1.0 else { return }  // Wait 1 sec
    
    frameCount += 1
    guard frameCount % 3 == 0 else { return }  // Process every 3rd frame
    
    // STEP 3: Extract Pixel Buffer
    guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
        return
    }
    
    // STEP 4: Background Processing (if enabled)
    if parent.isFacialRecognitionEnabled {
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.performSubjectDetection(pixelBuffer: pixelBuffer)
        }
    }
}

// STEP 5: Vision Framework Detection
private func performSubjectDetection(pixelBuffer: CVPixelBuffer) {
    let faceRequest = VNDetectFaceRectanglesRequest { [weak self] request, error in
        guard let self = self else { return }
        
        if let results = request.results as? [VNFaceObservation],
           let face = results.first {
            // STEP 6: Composition Analysis
            self.evaluateComposition(
                observation: face, 
                pixelBuffer: pixelBuffer
            )
        } else {
            // STEP 6b: Fallback to Human Detection
            self.performHumanDetection(pixelBuffer: pixelBuffer)
        }
    }
    
    let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:])
    try? handler.perform([faceRequest])
}

// STEP 7: Evaluate Composition
private func evaluateComposition(
    observation: VNDetectedObjectObservation,
    pixelBuffer: CVPixelBuffer
) {
    let result = parent.compositionManager.evaluate(
        observation: observation,
        frameSize: parent.frameSize,
        pixelBuffer: pixelBuffer
    )
    
    // STEP 8: Update UI on Main Thread
    DispatchQueue.main.async {
        self.parent.feedbackMessage = result.feedbackMessage
        self.parent.showFeedback = true
        self.parent.compositionScore = result.score
    }
}
```

**Threading**:
- **Main Thread**: Frame arrival, UI updates
- **Background (.userInitiated)**: Vision processing, composition analysis
- **Automatic**: SwiftUI rendering

**Performance**:
- Frame rate: 30 FPS
- Processing rate: 10 FPS (every 3rd frame)
- Vision latency: 50-150ms
- Total feedback delay: 100-200ms

---

## ğŸ“¸ Photo Capture Flow

### Complete Capture Pipeline

```
User Action
    â†“
[1] Button Tap Event (Main Thread)
    â†“
ContentView.capturePhoto()
    â†“
@State triggerCapture = true
    â†“
[2] SwiftUI Binding Update
    â†“
CameraView.updateUIView()
    â†“
Coordinator detects trigger change
    â†“
[3] Coordinator.capturePhoto()
    â†“
Configure AVCapturePhotoSettings
  â”œâ”€ Flash mode
  â”œâ”€ Quality settings
  â””â”€ Codec selection
    â†“
[4] photoOutput.capturePhoto(with: settings)
    â†“
Camera Hardware Capture (200-500ms)
    â†“
[5] Delegate Callback: photoOutput(_:didFinishProcessingPhoto:)
    â†“
Extract image data
    â†“
Convert to UIImage
    â†“
[6] PhotoManager.shared.savePhoto(image)
    â†“
Save to Documents  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Save to Photo Library
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Concurrent  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â†“             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â†“
Generate UUID filename              PHPhotoLibrary.shared().performChanges()
Create JPEG (90% quality)                      â†“
Write to file                          PHAssetChangeRequest
     â†“                                         â†“
[7] Update @Published photos array    Permission check
     â†“                                         â†“
DispatchQueue.main.async              Success/Error
     â†“
[8] PhotoManager broadcasts change
     â†“
SwiftUI Automatic Updates:
  â”œâ”€ PhotoAlbumView (gallery updates)
  â”œâ”€ ContentView (gallery glimpse appears)
  â””â”€ Haptic feedback triggers
```

### State Changes

| Step | State Variable | Owner | Effect |
|------|---------------|-------|--------|
| 1 | `triggerCapture` | ContentView | Button â†’ true |
| 2 | (binding propagation) | CameraView | Receives trigger |
| 3 | (internal) | Coordinator | Initiates capture |
| 6 | `photos` array | PhotoManager | New photo added |
| 8 | `showGalleryGlimpse` | ContentView | Gallery appears |

**Timing**:
- Button tap â†’ Capture start: <10ms
- Capture duration: 200-500ms
- File save: 50-150ms
- UI update: <16ms (1 frame)
- **Total**: ~500-1000ms

---

## ğŸ¨ Composition Analysis Data Flow

### Analysis Trigger â†’ UI Update

```
Vision Detection Complete
    â†“
VNDetectedObjectObservation
  â”œâ”€ boundingBox (subject location)
  â”œâ”€ confidence (detection quality)
  â””â”€ uuid (tracking)
    â†“
[1] CompositionManager.evaluate()
    â†“
Select Active Service
  â”œâ”€ .ruleOfThirds â†’ RuleOfThirdsService
  â”œâ”€ .centerFraming â†’ CenterFramingService
  â””â”€ .symmetry â†’ CenterFramingService (symmetry mode)
    â†“
[2] Service.evaluate(observation, frameSize, pixelBuffer)
    â†“
Algorithm Processing:
  â”œâ”€ Calculate subject position
  â”œâ”€ Determine composition alignment
  â”œâ”€ Generate score (0.0-1.0)
  â”œâ”€ Create directional feedback
  â””â”€ Generate overlay elements
    â†“
[3] Return CompositionResult
    {
        isWellComposed: Bool
        feedbackMessage: String
        overlayElements: [OverlayElement]
        score: Double
        compositionType: CompositionType
    }
    â†“
[4] Update @Published Properties
    â”œâ”€ lastResult = result
    â””â”€ (Optional) currentCompositionType
    â†“
[5] SwiftUI Automatic Updates (Main Thread)
    â”œâ”€ ContentView.feedbackMessage updates
    â”‚   â””â”€ Feedback text appears with animation
    â”œâ”€ CompositionOverlayView re-renders
    â”‚   â””â”€ Grid/crosshair updates position
    â””â”€ CompositionIndicatorView updates
        â””â”€ Score/status indicator changes
```

### Composition Type Change Flow

```
User Selects New Type (e.g., Center Framing)
    â†“
[1] CompositionPickerView Button Action
    â†“
compositionManager.switchToCompositionType(.centerFraming)
    â†“
[2] CompositionManager Method
    â”œâ”€ currentCompositionType = .centerFraming  (@Published)
    â”œâ”€ lastResult = nil  (clear previous result)
    â””â”€ (Service registry updates active service)
    â†“
[3] @Published Property Change Broadcasts
    â†“
[4] SwiftUI Automatic UI Updates:
    â”œâ”€ CompositionIndicatorView
    â”‚   â”œâ”€ Icon changes (grid â†’ crosshair)
    â”‚   â””â”€ Text updates
    â”œâ”€ CompositionOverlayView
    â”‚   â”œâ”€ Remove old overlays (grid lines)
    â”‚   â”œâ”€ Add new overlays (crosshair)
    â”‚   â””â”€ Animate transition (0.3s)
    â””â”€ CameraView (next frame)
        â””â”€ Uses new service for evaluation
```

---

## ğŸ“± Settings State Propagation

### Toggle Change â†’ Feature Update

```
User Toggles "Facial Recognition"
    â†“
[1] FrameSettingsView.Toggle
    â†“
@Binding var isFacialRecognitionEnabled
    â†“
[2] Binding Updates Parent
    â†“
ContentView: @State isFacialRecognitionEnabled = false
    â†“
[3] SwiftUI Binding Propagation
    â†“
CameraView(isFacialRecognitionEnabled: $isFacialRecognitionEnabled)
    â†“
[4] CameraView.updateUIView()
    â†“
coordinator.parent.isFacialRecognitionEnabled = false
    â†“
[5] Next Frame Processing
    â†“
captureOutput() checks:
if parent.isFacialRecognitionEnabled {
    performSubjectDetection()  // SKIPPED
}
    â†“
[6] Feature Disabled
    â””â”€ No Vision processing
    â””â”€ No composition analysis
    â””â”€ Better battery life
```

### Settings State Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ContentView    â”‚ (State Owner)
â”‚  @State vars    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ Pass as @Binding
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FrameSettingsView  â”‚ (Modal)
â”‚  @Binding vars     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Toggle     â”‚  â”‚ â† User interaction
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€ Updates binding â†’ Updates ContentView @State
                              â”‚
                              â”œâ”€ CameraView (receives binding)
                              â”‚   â””â”€ Behavior changes
                              â”‚
                              â””â”€ CompositionManager (direct property)
                                  â””â”€ Analysis enabled/disabled
```

---

## ğŸ–¼ï¸ Image Editing Data Flow

### Filter Application Pipeline

```
User Selects Filter
    â†“
[1] ImagePreviewView Filter Picker
    â†“
selectedFilter = "Bourbon 64"
    â†“
[2] Trigger Filter Application
    â†“
FilterManager.shared.applyFilter(filter, to: image)
    â†“
[3] LUTApplier.applyLUT()
    â”œâ”€ Load .CUBE file (cached)
    â”œâ”€ Parse LUT data
    â”œâ”€ Create CIFilter.colorCube
    â”œâ”€ Apply to CIImage
    â””â”€ Render with Metal-accelerated CIContext
    â†“
[4] Return Filtered UIImage
    â†“
[5] Update State
@State var previewImage = filteredImage
    â†“
[6] SwiftUI Update
    â””â”€ Image view re-renders with filtered image
```

### Background Blur Pipeline

```
User Adjusts Blur Slider
    â†“
[1] Slider Value Change (0-40)
@State var blurIntensity: Float = 15.0
    â†“
[2] Debounce (150ms)
    â”œâ”€ Cancel previous work item
    â””â”€ Schedule new work item
    â†“
[3] BackgroundBlurManager.generateBlurPreview()
    â†“
[4] Person Segmentation (if not cached)
    â”œâ”€ VNGeneratePersonSegmentationRequest
    â”œâ”€ Quality: .accurate
    â”œâ”€ Process at preview resolution (400Ã—600)
    â””â”€ Generate mask (white=person, black=background)
    â†“
[5] Blur Application
    â”œâ”€ CIFilter.gaussianBlur (radius=blurIntensity)
    â”œâ”€ CIFilter.affineClamp (edge prevention)
    â””â”€ Apply to background only
    â†“
[6] Mask Blending (Dual-Method)
    â”œâ”€ Method 1: CIFilter.blendWithMask
    â”‚   â””â”€ Composite sharp subject + blurred background
    â””â”€ Method 2: Manual compositing (fallback)
        â””â”€ (original Ã— personMask) + (blurred Ã— bgMask)
    â†“
[7] Cache Result
    â”œâ”€ maskCache.setObject(mask, forKey: key)
    â””â”€ blurCache.setObject(result, forKey: key)
    â†“
[8] Update State
@State var previewImage = blurredImage
    â†“
[9] SwiftUI Update
    â””â”€ Preview updates in real-time
```

**Performance**:
- Segmentation (cached): <1ms
- Segmentation (new): 15-25ms (preview), 200-400ms (full)
- Blur application: 10-20ms
- Total: 20-50ms for cached, 100-200ms for new

---

## ğŸ’¾ Photo Management Data Flow

### Gallery Update Flow

```
PhotoManager.savePhoto() Called
    â†“
[1] Generate UUID Filename
filename = "\(UUID().uuidString).jpg"
    â†“
[2] JPEG Compression (90% quality)
jpegData = image.jpegData(compressionQuality: 0.9)
    â†“
[3] Concurrent Operations
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚                 â”‚
    â–¼                 â–¼                 â–¼
Save to Documents  Update Array   Save to Library
FileManager write  @Published     PHPhotoLibrary
    â”‚              photos.insert()     â”‚
    â”‚                   â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
         [4] @Published Property Change
                        â†“
         [5] SwiftUI Automatic Updates
                        â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                       â”‚
            â–¼                       â–¼
    PhotoAlbumView          ContentView
    (Gallery grid)      (Gallery glimpse)
            â”‚                       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              [6] UI Animations
                â”œâ”€ Gallery glimpse slides up
                â”œâ”€ Thumbnail appears in grid
                â””â”€ Haptic feedback
```

### Photo Deletion Flow

```
User Confirms Delete
    â†“
[1] PhotoAlbumView.deletePhoto(photoItem)
    â†“
[2] PhotoManager.shared.deletePhoto(photoItem)
    â†“
[3] File System Operations
    â”œâ”€ FileManager.removeItem(at: photoItem.url)
    â””â”€ Error handling
    â†“
[4] Update @Published Array
photos.removeAll { $0.id == photoItem.id }
    â†“
[5] @Published Change Broadcast
    â†“
[6] SwiftUI Automatic Update
    â””â”€ PhotoAlbumView removes thumbnail
        â””â”€ Animated removal transition
```

---

## ğŸ”„ Asynchronous Operation Patterns

### Background Processing Pattern

```swift
// Pattern: Background work â†’ Main thread UI update

// STEP 1: Dispatch to background
DispatchQueue.global(qos: .userInitiated).async { [weak self] in
    guard let self = self else { return }
    
    // STEP 2: Heavy processing
    let result = performExpensiveOperation()
    
    // STEP 3: Update UI on main thread
    DispatchQueue.main.async {
        self.updateState(result)  // Triggers SwiftUI update
    }
}
```

### Debounced Updates Pattern

```swift
// Pattern: Rapid user input â†’ Debounced processing

private var workItem: DispatchWorkItem?

func handleRapidInput(value: Float) {
    // Cancel previous work
    workItem?.cancel()
    
    // Schedule new work
    let newWorkItem = DispatchWorkItem { [weak self] in
        guard let self = self else { return }
        self.processValue(value)
    }
    workItem = newWorkItem
    
    // Execute after delay
    DispatchQueue.main.asyncAfter(
        deadline: .now() + 0.15,
        execute: newWorkItem
    )
}
```

### Concurrent Operations Pattern

```swift
// Pattern: Parallel independent operations

async let task1 = performOperation1()
async let task2 = performOperation2()
async let task3 = performOperation3()

let (result1, result2, result3) = await (task1, task2, task3)

// All operations completed
processResults(result1, result2, result3)
```

---

## ğŸ“Š State Update Frequency Analysis

| Operation | Frequency | Thread | Latency |
|-----------|-----------|--------|---------|
| Camera frames | 30 FPS | Main | 33ms |
| Frame processing | 10 FPS | Background | 100-200ms |
| Composition updates | ~5-10 FPS | Main | <16ms |
| Slider changes | ~10-20/sec | Main | Debounced 150ms |
| Photo save | On-demand | Background | 200-500ms |
| Settings toggle | On-demand | Main | <16ms |

---

## ğŸ¯ Data Flow Best Practices

### âœ… DO:
- Process heavy operations on background threads
- Update UI only on main thread
- Debounce rapid user inputs
- Use weak references in async closures
- Cache expensive computations
- Throttle high-frequency updates

### âŒ DON'T:
- Block main thread with heavy processing
- Update state in background threads (use DispatchQueue.main.async)
- Process every camera frame (throttle)
- Perform expensive operations on state changes
- Create retain cycles in closures
- Update UI faster than screen refresh rate (60 FPS)

---

## ğŸ“š Related Documentation

- [STATE_MANAGEMENT.md](./STATE_MANAGEMENT.md) - State patterns
- [ARCHITECTURE_OVERVIEW.md](./ARCHITECTURE_OVERVIEW.md) - System architecture
- [COMPONENT_MAP.md](./COMPONENT_MAP.md) - Component relationships
- [Application Flows](../3_Application_Flows/FLOWS_INDEX.md) - End-to-end flows
- [PERFORMANCE_OVERVIEW.md](../6_Performance/PERFORMANCE_OVERVIEW.md) - Performance details

---

**Document Status**: âœ… Complete  
**Last Updated**: October 30, 2025  
**Maintained By**: Development Team

